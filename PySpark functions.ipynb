{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import Row\n",
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[11] at parallelize at PythonRDD.scala:480\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n",
      "[(0, 'Touche'), (1, 'Touche'), (4, 'Not valid!'), (9, 'Touche'), (16, 'Touche'), (25, 'Touche'), (36, 'Touche'), (49, 'Not valid!'), (64, 'Touche'), (81, 'Touche'), (100, 'Touche'), (121, 'Touche'), (144, 'Touche'), (169, 'Touche'), (196, 'Touche'), (225, 'Touche'), (256, 'Touche'), (289, 'Touche'), (324, 'Touche'), (361, 'Touche'), (400, 'Not valid!'), (441, 'Not valid!'), (484, 'Not valid!'), (529, 'Touche'), (576, 'Touche'), (625, 'Touche'), (676, 'Touche'), (729, 'Touche'), (784, 'Touche'), (841, 'Touche'), (900, 'Touche'), (961, 'Touche'), (1024, 'Touche'), (1089, 'Touche'), (1156, 'Touche'), (1225, 'Touche'), (1296, 'Touche'), (1369, 'Touche'), (1444, 'Touche'), (1521, 'Touche'), (1600, 'Touche'), (1681, 'Touche'), (1764, 'Touche'), (1849, 'Touche'), (1936, 'Touche'), (2025, 'Touche'), (2116, 'Touche'), (2209, 'Touche'), (2304, 'Touche'), (2401, 'Touche'), (2500, 'Touche'), (2601, 'Touche'), (2704, 'Touche'), (2809, 'Touche'), (2916, 'Touche'), (3025, 'Touche'), (3136, 'Touche'), (3249, 'Touche'), (3364, 'Touche'), (3481, 'Touche'), (3600, 'Touche'), (3721, 'Touche'), (3844, 'Touche'), (3969, 'Touche'), (4096, 'Not valid!'), (4225, 'Not valid!'), (4356, 'Not valid!'), (4489, 'Not valid!'), (4624, 'Not valid!'), (4761, 'Not valid!'), (4900, 'Not valid!'), (5041, 'Not valid!'), (5184, 'Not valid!'), (5329, 'Not valid!'), (5476, 'Not valid!'), (5625, 'Not valid!'), (5776, 'Not valid!'), (5929, 'Not valid!'), (6084, 'Not valid!'), (6241, 'Not valid!'), (6400, 'Not valid!'), (6561, 'Not valid!'), (6724, 'Not valid!'), (6889, 'Not valid!'), (7056, 'Not valid!'), (7225, 'Not valid!'), (7396, 'Not valid!'), (7569, 'Not valid!'), (7744, 'Not valid!'), (7921, 'Not valid!'), (8100, 'Not valid!'), (8281, 'Not valid!'), (8464, 'Not valid!'), (8649, 'Not valid!'), (8836, 'Not valid!'), (9025, 'Not valid!'), (9216, 'Not valid!'), (9409, 'Not valid!'), (9604, 'Not valid!'), (9801, 'Not valid!')]\n"
     ]
    }
   ],
   "source": [
    "test = sc.parallelize(zip(range(100),range(100,200)))\n",
    "print(test)\n",
    "\n",
    "# Filter on only the even first values. \n",
    "test.filter(lambda x:x[0] % 2 == 0)\n",
    "\n",
    "# Map the second values to a square. \n",
    "#    Return a new RDD by applying a function to each element of this RDD.\n",
    "\n",
    "# Square each of the values of the tuple\n",
    "# print(test.map(lambda x:x[0] ** 2 ).collect())\n",
    "\n",
    "# Use a UserDefinedFunction to 'map' the square to a function. \n",
    "def square_function(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "# Create a new RDD and apply the square function. \n",
    "test2 = sc.parallelize(range(10))\n",
    "print(test2.map(square_function).collect())\n",
    "\n",
    "# Apply the square function to a multi-column RDD. \n",
    "squared_list = test.map(lambda x:square_function(x[0]))\n",
    "print(squared_list.collect())\n",
    "\n",
    "# Filter the squared values for the values less than 5000 and not starting with 4\n",
    "def less_than_5000_not_four(x):\n",
    "    if x < 5000 and str(x)[0] != '4':\n",
    "        return_val = 'Touche'\n",
    "    else: \n",
    "        return_val = \"Not valid!\"\n",
    "    return (x,return_val)\n",
    "\n",
    "print(squared_list.map(lambda x:less_than_5000_not_four(x)).collect())\n",
    "\n",
    "# Create an RDD of the squared list tuple\n",
    "touche_binned_RDD = squared_list.map(lambda x:less_than_5000_not_four(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], 'None', [2, 2, 2, 2, 2], 'None', [4, 4, 4, 4, 4], 'None', [6, 6, 6, 6, 6], 'None', [8, 8, 8, 8, 8], 'None', [10, 10, 10, 10, 10], 'None', [12, 12, 12, 12, 12], 'None', [14, 14, 14, 14, 14], 'None', [16, 16, 16, 16, 16], 'None', [18, 18, 18, 18, 18], 'None', [20, 20, 20, 20, 20], 'None', [22, 22, 22, 22, 22], 'None', [24, 24, 24, 24, 24], 'None', [26, 26, 26, 26, 26], 'None', [28, 28, 28, 28, 28], 'None', [30, 30, 30, 30, 30], 'None', [32, 32, 32, 32, 32], 'None', [34, 34, 34, 34, 34], 'None', [36, 36, 36, 36, 36], 'None', [38, 38, 38, 38, 38], 'None', [40, 40, 40, 40, 40], 'None', [42, 42, 42, 42, 42], 'None', [44, 44, 44, 44, 44], 'None', [46, 46, 46, 46, 46], 'None', [48, 48, 48, 48, 48], 'None', [50, 50, 50, 50, 50], 'None', [52, 52, 52, 52, 52], 'None', [54, 54, 54, 54, 54], 'None', [56, 56, 56, 56, 56], 'None', [58, 58, 58, 58, 58], 'None', [60, 60, 60, 60, 60], 'None', [62, 62, 62, 62, 62], 'None', [64, 64, 64, 64, 64], 'None', [66, 66, 66, 66, 66], 'None', [68, 68, 68, 68, 68], 'None', [70, 70, 70, 70, 70], 'None', [72, 72, 72, 72, 72], 'None', [74, 74, 74, 74, 74], 'None', [76, 76, 76, 76, 76], 'None', [78, 78, 78, 78, 78], 'None', [80, 80, 80, 80, 80], 'None', [82, 82, 82, 82, 82], 'None', [84, 84, 84, 84, 84], 'None', [86, 86, 86, 86, 86], 'None', [88, 88, 88, 88, 88], 'None', [90, 90, 90, 90, 90], 'None', [92, 92, 92, 92, 92], 'None', [94, 94, 94, 94, 94], 'None', [96, 96, 96, 96, 96], 'None', [98, 98, 98, 98, 98], 'None']\n"
     ]
    }
   ],
   "source": [
    "def get_even_value_list(x):\n",
    "    if x % 2 == 0:\n",
    "        return_val = [x] * 5\n",
    "    else:\n",
    "        return_val = \"None\"\n",
    "    return return_val\n",
    "\n",
    "\n",
    "print(test.map(lambda x:get_even_value_list(x[0])).collect())\n",
    "\n",
    "\n",
    "## What does Row do in a map function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Turn RDD into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Logic='Not valid!', avg(Number)=5960.585365853659), Row(Logic='Touche', avg(Number)=1423.1525423728813)]\n",
      "[Row(Logic='Not valid!', max(Number)=9801), Row(Logic='Touche', max(Number)=3969)]\n"
     ]
    }
   ],
   "source": [
    "# Using groupBy to take aggregate of a column \n",
    "# First convert the RDD to a dataframe. \n",
    "touche_binned_df = sqlContext.createDataFrame(touche_binned_RDD,['Number', 'Logic'])\n",
    "\n",
    "# Then apply a groupBy and take the average on the number column. \n",
    "print(touche_binned_df.groupBy('Logic').agg({'Number':'mean'}).collect())\n",
    "\n",
    "print(touche_binned_df.groupBy('Logic').agg({'Number':'max'}).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode a column into individual rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame with multiple entries in a single cell: \n",
      " [Row(a=1, my_list=[1, 2, 3, 4])]\n",
      " \n",
      " Post explode dataframe: \n",
      " [Row(int_rows=1), Row(int_rows=2), Row(int_rows=3), Row(int_rows=4)]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD to explode by the row values. \n",
    "explode_df = spark.createDataFrame([Row(a = 1, my_list = [1,2,3,4])])\n",
    "print(\"Data frame with multiple entries in a single cell: \\n {0}\".format(explode_RDD.collect()))\n",
    "\n",
    "# Explode the my_list cell list to multiple rows.\n",
    "post_explode_df = explode_df.select(explode('my_list').alias('int_rows')).collect()\n",
    "\n",
    "print(\" \\n Post explode dataframe: \\n {0}\".format(post_explode_df))\n",
    "\n",
    "# Explode the column while preserving the rest of the dataframe. \n",
    "post_explode_df = explode_df.withColumn(\"exploded_col\", col=explode('my_list')).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
